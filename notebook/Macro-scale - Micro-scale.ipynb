{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import powerlaw\n",
    "import imageio\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from fa2 import ForceAtlas2\n",
    "\n",
    "# create number for each group to allow use of colormap\n",
    "from itertools import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Utilyties.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage(part, whole):\n",
    "  percentage = 100 * float(part)/float(whole)\n",
    "  return str(round(percentage, 2)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = \"\"\n",
    "data = read_data(path+'../data/data_complete.json')\n",
    "\n",
    "G = init_network(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = giant_component(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ForceAtlas2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forceatlas2 = ForceAtlas2(\n",
    "                # Behavior alternatives\n",
    "                outboundAttractionDistribution=False,  # Dissuade hubs\n",
    "                linLogMode=False,  # NOT IMPLEMENTED\n",
    "                adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
    "                edgeWeightInfluence=1.0,\n",
    "\n",
    "                # Performance\n",
    "                jitterTolerance=1.0,  # Tolerance\n",
    "                barnesHutOptimize=True,\n",
    "                barnesHutTheta=1.2,\n",
    "                multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                # Tuning\n",
    "                scalingRatio=2.0,\n",
    "                strongGravityMode=False,\n",
    "                gravity=1.0,\n",
    "\n",
    "                # Log\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### to get the positions use the file pos.pkl ###\n",
    "\n",
    "# asciiattention! This process takes a lot of time\n",
    "positions = forceatlas2.forceatlas2_networkx_layout(G0, pos=None, iterations=1000)\n",
    "\n",
    "# saving the positions in a file\n",
    "a_file = open(\"pos.pkl\", \"wb\") \n",
    "pickle.dump(positions, a_file) \n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading positions from pos.pkl\n",
    "a_file = open(path+\"/pos.pkl\", \"rb\")\n",
    "positions = pickle.load(a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "sns.set_style(style='white')\n",
    "figure(figsize=(10, 10))\n",
    "\n",
    "nx.draw_networkx_nodes(G0, positions, node_size=2, with_labels=False, \n",
    "                       node_color=[G0.nodes[node]['classification'] for node in G0.nodes()], \n",
    "                       cmap = 'coolwarm', alpha=0.4)\n",
    "nx.draw_networkx_edges(G0, positions, edge_color=\"grey\", alpha=0.2)\n",
    "\n",
    "x = np.linspace(-3000, 3000, 5)\n",
    "plt.plot(x, -1.1*x+80, linestyle='-', color='black')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning 'red' or 'blue' value to the \"echo_chaber\" attribute to network nodes based\n",
    "\n",
    "for p in positions:\n",
    "    if (positions[p][1] + 1.1*positions[p][0] - 80 > 0):\n",
    "        G0.nodes[p]['echo_chamber'] = 'blue'\n",
    "    else:\n",
    "        G0.nodes[p]['echo_chamber'] = 'red'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_red = len([x for x,y in G0.nodes(data=True) if y['echo_chamber']=='red'])\n",
    "n_blue = len([x for x,y in G0.nodes(data=True) if y['echo_chamber']=='blue'])\n",
    "\n",
    "print(f\"Echo chambers dimensions:\\n\\nRed\\t{n_red}\\nBlue\\t{n_blue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of two subgraphs, one with the nodes and links of the section below the line (subgraph R), and one with those above it (subgraph B).\n",
    "H_red = G0.subgraph([x for x,y in G0.nodes(data=True) if y['echo_chamber']=='red'])\n",
    "H_blue = G0.subgraph([x for x,y in G0.nodes(data=True) if y['echo_chamber']=='blue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H0_red = giant_component(H_red) #Sottografo R\n",
    "H0_blue = giant_component(H_blue) #Sottografo B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studio delle partizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolo della percentuale di utenti a favore, contrari e neutri \n",
    "def partitions_profiling(g):\n",
    "    # percentuale di pro\n",
    "    pros = len([x for x,y in g.nodes(data=True) if y['cont_classification']<= -0.5])\n",
    "    cons = len([x for x,y in g.nodes(data=True) if y['cont_classification']>= 0.5])\n",
    "    neutrals = (g.number_of_nodes() - pros - cons)\n",
    "    average = Average([y['cont_classification'] for x,y in g.nodes(data=True)])\n",
    "    \n",
    "    print(f\"N. supporters: {percentage(pros, g.number_of_nodes())}\\n\"+\n",
    "          f\"N. opponents: {percentage(cons, g.number_of_nodes())}\\n\"+\n",
    "          f\"N. neutrals or unclassifiable: {percentage(neutrals, g.number_of_nodes())}\\n\"+\n",
    "          f\"Average opinion: {round(average,2)}\")\n",
    "    #return pros, cons, neutrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Disconnected nodes in the EC Red: {H_red.number_of_nodes() - H0_red.number_of_nodes()}\")\n",
    "print(f\"Disconnected nodes in the EC Blue: {H_blue.number_of_nodes() - H0_blue.number_of_nodes()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_info(H0_red, 'Echo chamber - Red') #Sottografo R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_profiling(H0_red) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_info(H0_blue, 'Echo chamber - Blue') #Sottografo B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions_profiling(H0_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of edges between the two echo chambers: {G0.number_of_edges() - (H0_red.number_of_edges()+H0_blue.number_of_edges())} ({round((((G0.number_of_edges() - (H0_red.number_of_edges()+H0_blue.number_of_edges()))/G0.number_of_edges())*100), 2)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hubs analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "node_degree = G.degree()\n",
    "node_degree_r = H0_red.degree()\n",
    "node_degree_b = H0_blue.degree()\n",
    "\n",
    "hubs = sorted(node_degree, key=itemgetter(1), reverse=True)\n",
    "hubs_r = sorted(node_degree_r, key=itemgetter(1), reverse=True)\n",
    "hubs_b = sorted(node_degree_b, key=itemgetter(1), reverse=True)\n",
    "\n",
    "C = nx.get_node_attributes(G, 'cont_classification')\n",
    "C_r = nx.get_node_attributes(H0_red, 'cont_classification')\n",
    "C_b = nx.get_node_attributes(H0_blue, 'cont_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 #percentage per thousand of hub nodes on all nodes\n",
    "\n",
    "npm = int(round(G.number_of_nodes()*n/1000,0)) #percentace of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "average_degree_red = 0\n",
    "average_degree_blue = 0\n",
    "\n",
    "n_red = 0\n",
    "n_blue = 0\n",
    "\n",
    "print(f\"\\nList of {int(npm)} hubs ({n}%° of nodes of the entire network sorted by degree) \\n\")\n",
    "print(\"Rank\\tEC\\tUsername\\tC\\u1D64\\tDegree\")\n",
    "\n",
    "i=1\n",
    "for h in hubs[:npm]: #2%° dei nodi in base al grado\n",
    "    if H0_red.has_node(h[0]):\n",
    "        print(f\"{i}.\\tR\\t{h[0]} \\t{round(C[h[0]],1)} \\t\\t{h[1]}\")\n",
    "        average_degree_red += h[1]\n",
    "        n_red += 1\n",
    "    else:    \n",
    "        print(f\"{i}.\\tB\\t{h[0]} \\t{round(C[h[0]],1)} \\t\\t{h[1]}\")\n",
    "        average_degree_blue += h[1]\n",
    "        n_blue += 1\n",
    "    i+=1   \n",
    "    \n",
    "print(f\"\\nAverage hubs degree in the EC Red\\t{round(average_degree_red/n_red,1)}\")\n",
    "print(f\"Average hubs degree in the EC Blue\\t{round(average_degree_blue/n_blue,1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "c = nx.Graph()\n",
    "\n",
    "c_red = nx.Graph()\n",
    "c_blue = nx.Graph()\n",
    "\n",
    "n_nodes = []\n",
    "n_nodes_favore = []\n",
    "n_nodes_contro = []\n",
    "n_nodes_neutri = []\n",
    "\n",
    "r_hubs = 0\n",
    "b_hubs = 0\n",
    "n_hubs = 0\n",
    "\n",
    "l_r_hubs = []\n",
    "l_b_hubs = []\n",
    "l_n_hubs = []\n",
    "\n",
    "perc_net = []\n",
    "r_perc_ego = []\n",
    "b_perc_ego = []\n",
    "\n",
    "time = 1\n",
    "\n",
    "for snap, dates in zip(snapshots, ranges):\n",
    "    \n",
    "    print(f\"--- Network dal: {dates[0]} al {dates[-1]} (Tempo {time})--- \\n\")\n",
    "    build_network(snap, G)\n",
    "    \n",
    "    n_nodes.append(G.number_of_nodes())\n",
    "    n_nodes_contro.append(G.subgraph([x for x,y in G0.nodes(data=True) if y['cont_classification']>=0.5]).number_of_nodes())\n",
    "    n_nodes_favore.append(G.subgraph([x for x,y in G0.nodes(data=True) if y['cont_classification']<=-0.5]).number_of_nodes())\n",
    "    n_nodes_neutri.append(G.subgraph([x for x,y in G0.nodes(data=True) if (y['cont_classification']>-0.5) & (y['cont_classification']<0.5)]).number_of_nodes())\n",
    "    \n",
    "    for node in real_hubs:\n",
    "        if G.has_node(node):\n",
    "            n_hubs += 1\n",
    "            node_ego = nx.ego_graph(G, node)\n",
    "            c = nx.compose(c, node_ego)\n",
    "            if node in real_hub_red:\n",
    "                c_red = nx.compose(c_red, node_ego)\n",
    "                r_hubs += 1\n",
    "            elif node in real_hub_blue:\n",
    "                c_blue = nx.compose(c_blue, node_ego)\n",
    "                b_hubs += 1\n",
    "                \n",
    "    l_r_hubs.append(r_hubs)\n",
    "    l_b_hubs.append(b_hubs)\n",
    "    l_n_hubs.append(n_hubs)\n",
    "    \n",
    "    perc_net.append(round(c.number_of_nodes()/G.number_of_nodes()*100, 2))\n",
    "    r_perc_ego.append(round(c_red.number_of_nodes()/c.number_of_nodes()*100, 2))\n",
    "    b_perc_ego.append(round(c_blue.number_of_nodes()/c.number_of_nodes()*100, 2))\n",
    "    \n",
    "    print(f\"Hubs: {n_hubs}\" + \n",
    "          f\"\\nNodes connected to the hubs: {c.number_of_nodes()} ({perc_net[-1]}% of the network)\" + #Numero totale di nodi dell'unione delle ego-networks degli hubs\n",
    "          f\"\\nHubs in the subgraph R: {r_hubs}\" +\n",
    "          f\"\\n\\tNodes connected to the hubs in the subgraph R: {c_red.number_of_nodes()} ({round(c_red.number_of_nodes()/G.number_of_nodes()*100, 2)}% of the network\" +\n",
    "          f\"\\nHubs in the subgraph B: {b_hubs}\" +\n",
    "          f\"\\n\\tNodes connected to the hubs in the subgraph B: {c_blue.number_of_nodes()} ({round(c_blue.number_of_nodes()/G.number_of_nodes()*100, 2)}% of the network\" + \n",
    "          f\"\\nNodes connected to both hubs in subgraph R and B: {-c.number_of_nodes()+c_red.number_of_nodes()+c_blue.number_of_nodes()} ({round((-c.number_of_nodes()+c_red.number_of_nodes()+c_blue.number_of_nodes())/G.number_of_nodes()*100, 2)}% of the network)\\n\\n\")\n",
    "    \n",
    "    r_hubs = 0\n",
    "    b_hubs = 0\n",
    "    n_hubs = 0\n",
    "    time += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7']\n",
    "df_net_growth = pd.DataFrame([n_nodes_favore, n_nodes_contro, n_nodes], \n",
    "                                columns = columns, \n",
    "                                index = ['pro', 'cons', 'all'])\n",
    "df_net_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Turkey - Italy\", \n",
    "          \"Italy - Switzerland\", \n",
    "          \"Italy - Wales\", \n",
    "          \"Italy - Austria\", \n",
    "          \"Belgium - Italy\", \n",
    "          \"Italy - Spain\", \n",
    "          \"Italy - England\"]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "sns.set(rc={'figure.figsize':(17,4.8), \"lines.linewidth\": 0.9, \"grid.linewidth\": 0.4}, font_scale=1.3)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=True)\n",
    "\n",
    "y=[n_nodes_favore, n_nodes_contro, n_nodes_neutri]\n",
    "ax[0].stackplot(x,y, \n",
    "                colors = ['#3480b9', '#b1182b', '#d4d4d452'],  alpha=.7,  \n",
    "                labels=['pros','cons', 'neutral'], \n",
    "                linewidth=2)\n",
    "ax[0].set_ylabel('Number of nodes', rotation=90, labelpad=20)\n",
    "ax[0].set_xticks(x)\n",
    "ax[0].legend(loc='upper left')\n",
    "ax[0].set_xticklabels(labels, rotation=20)\n",
    "\n",
    "ax[1].plot(perc_net,\n",
    "         linestyle='-',\n",
    "         marker='o', color='black', linewidth=2.0)\n",
    "\n",
    "\n",
    "ax2 = ax[1].twinx()\n",
    "ax2.bar(x - width/2, l_r_hubs, width, color = '#b1182b', alpha=.7, label=r'$\\in$ Subgraph R')\n",
    "ax2.bar(x + width/2, l_b_hubs, width, color = '#3480b9', alpha=.7, label=r'$\\in$ Subgraph B')\n",
    "\n",
    "ax2.set_ylabel('Number of hubs', rotation=-90, labelpad=20)\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "# move ax in front\n",
    "ax[1].set_zorder(1)\n",
    "ax[1].patch.set_visible(False)\n",
    "\n",
    "ax[1].set_ylabel('Percentage of nodes (%)', labelpad=20)\n",
    "ax[1].set_xticks(x)\n",
    "ax[1].yaxis.grid(False)\n",
    "\n",
    "sns.despine(top=True, right=True, left=False, bottom=True, offset=10, trim=True, ax = ax[0])\n",
    "sns.despine(top=True, right=False, left=False, bottom=True, offset=10, trim=True, ax = ax2)\n",
    "sns.despine(top=True, right=False, left=False, bottom=True, offset=10, trim=True, ax = ax[1])\n",
    "sns.despine(offset=10, trim=True, ax = ax[1])\n",
    "\n",
    "ax[1].set_xticklabels(labels, rotation=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make our research more consistent, we choose to carry out this analysis on the users who wrote at least two tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots = get_snapshot(path+\"../data/data_complete.json\", ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "n_users = df.user.value_counts()\n",
    "user_list_occ = df[df.user.isin(n_users.index[n_users.gt(1)])].groupby('user').mean() # lista di utenti autori di almeno 2 tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_opinion(G):\n",
    "    for node in G.nodes():\n",
    "        if G.nodes[node]['cont_classification'] < 0.5 and G.nodes[node]['cont_classification'] > -0.5:\n",
    "            G.nodes[node]['cont_classification'] = 0\n",
    "        elif G.nodes[node]['cont_classification'] >= 0.5:\n",
    "            G.nodes[node]['cont_classification'] = 1\n",
    "        else:\n",
    "            G.nodes[node]['cont_classification'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ass_mix(G):\n",
    "    discretize_opinion(G) # discretizza l'opinione in -1 (a favore), 1 (contrari), 0 (neutri/non classificabili)\n",
    "    return nx.attribute_assortativity_coefficient(G, \"cont_classification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# studio sulla  opinione media dei vicini CN(u) rispetto all’opinione media di un utente Cu\n",
    "def neighbors_av_opinion(G, T, lista_ass_mix): \n",
    "    nx.set_node_attributes(G, 0, \"neighbours_opinion\") # inizializzazione dell'attributo\n",
    "    \n",
    "    # calcolo e assegnazione del valore dell'attributo neighbours_opinion ad ogni nodo\n",
    "    for node in G.nodes():\n",
    "        if node in user_list_occ.index: \n",
    "            for n in(G.neighbors(node)):\n",
    "                G.nodes[node]['neighbours_opinion'] += G.nodes[n][\"cont_classification\"]\n",
    "            if (G.degree[node] != 0): \n",
    "                G.nodes[node]['neighbours_opinion'] = G.nodes[node]['neighbours_opinion']/G.degree[node]\n",
    "            else:\n",
    "                G.nodes[node]['neighbours_opinion'] = G.nodes[node]['cont_classification']\n",
    "    \n",
    "    # creazione del dizionario\n",
    "    n_class = {}\n",
    "    for node in G.nodes():\n",
    "        if node in user_list_occ.index:\n",
    "            n_class[node] = [G.nodes[node]['cont_classification']]\n",
    "            n_class[node].append(G.nodes[node]['neighbours_opinion'])\n",
    "    \n",
    "    # creazione del dataframe\n",
    "    df_class = pd.DataFrame.from_dict(n_class, orient='index',\n",
    "                           columns=['opinion','neighbours_opinion'])\n",
    "    \n",
    "    # discretizzazione dell'opinione \n",
    "    df_class[\"class\"] = np.where(\n",
    "        df_class[\"opinion\"] >= 0.5, 'contro', \n",
    "        np.where(df_class[\"opinion\"] <= -0.5, 'pro', 'neutro')\n",
    "    )\n",
    "    \n",
    "    ### PLOT ###\n",
    "    plt.figure(figsize=(6,6))\n",
    "    ax = plt.axes()\n",
    "    ax.set_facecolor(\"black\")\n",
    "    \n",
    "    ax = sns.kdeplot(data = df_class,  x = \"opinion\", y = \"neighbours_opinion\", \n",
    "                fill=True, thresh=0, levels=100, cmap=\"CMRmap\") #ax=axes[T]) #o mako\n",
    "    ax.set(xlim=(-3, 3), ylim=(-3, 3))\n",
    "    ax.set_xlabel('$C_{u}$', fontsize = 26)\n",
    "    ax.set_ylabel('$C_{N(u)}$', fontsize = 26)\n",
    "    \n",
    "    # calcolo del p-value e del coefficiente di pearson \n",
    "    r, p = scipy.stats.pearsonr(df_class['opinion'], df_class['neighbours_opinion'])\n",
    "    print(f\"Pearson coefficient: {round(r,2)}\\tp-value: {round(p,4)} \\n\")\n",
    "    \n",
    "    # calcolo dell'assortative mixing \n",
    "    G_tmp = G.copy()\n",
    "    lista_ass_mix.append(get_ass_mix(G_tmp))\n",
    "    \n",
    "    ax.tick_params(axis='both', labelsize=16)\n",
    "    \n",
    "    tempo = T+1\n",
    "    ax.text(x=0.04, y=0.96, transform = ax.transAxes, s=\"$ρ = %.2f$\" % r,\\\n",
    "        fontsize=26, verticalalignment='top', horizontalalignment='left', color='white')\n",
    "    ax.text(x=0.04, y=0.84, transform = ax.transAxes, s=\"$r = %.2f$\" % lista_ass_mix[T],\\\n",
    "        fontsize=26, verticalalignment='top', horizontalalignment='left', color='white')\n",
    "    ax.text(x=0.80, y=0.13, transform = ax.transAxes, s=r\"t = %.0f\" % tempo,\\\n",
    "        fontsize=26, verticalalignment='top', horizontalalignment='left', color='white')\n",
    "    \n",
    "    # create file name and append it to a list\n",
    "    #filename = f'Density_2tweets_{T}.png'\n",
    "    #filenames.append(filename)\n",
    "    \n",
    "    # save frame\n",
    "    #plt.savefig(filename, transparent=True)\n",
    "    #plt.close()\n",
    "    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G=nx.Graph()\n",
    "T = 0\n",
    "lista_ass_mix = []\n",
    "filenames = []   \n",
    "\n",
    "for snap in snapshots:\n",
    "    build_network(snap, G)\n",
    "    neighbors_av_opinion(G, T, lista_ass_mix)\n",
    "    T += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "66b3e2fd3f45181390eec52825d6f63d319e1dfc034c5e0bfab24aa05acc1618"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
